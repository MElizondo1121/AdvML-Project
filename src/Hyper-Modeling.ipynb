{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4337bb",
   "metadata": {},
   "source": [
    "# Modeling - Hyperparameter tuning (Adv-ML)\n",
    "\n",
    "    1. Gradient Boosting Trees\n",
    "    2. XGBoost\n",
    "    3. LightGBM\n",
    "    4. CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816c9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2dc230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_processed.csv', header=0)\n",
    "test = pd.read_csv('../data/test_processed.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cc91df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of Machine Failure:\n",
      "Value 0: 134281\n",
      "Value 1: 2148\n"
     ]
    }
   ],
   "source": [
    "failure_counts = train['Machine failure'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Occurrences of Machine Failure:\")\n",
    "print(\"Value 0:\", failure_counts[0])\n",
    "print(\"Value 1:\", failure_counts[1])\n",
    "\n",
    "X = train.drop(['Machine failure'], axis=1)\n",
    "y = train['Machine failure'].values\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80997ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e7db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_dist_rfc = { \n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "random_search_rfc = RandomizedSearchCV(estimator=rfc, param_distributions=param_dist_rfc, cv=3)\n",
    "random_search_rfc.fit(X_train_pca, y_train)\n",
    "\n",
    "rfc_predictions = random_search_rfc.predict(X_test_pca) \n",
    "print(classification_report(y_val, rfc_predictions)) \n",
    "print(confusion_matrix(y_val, rfc_predictions))\n",
    "print(\"Best Parameters for RFC:\", random_search_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d49614",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_val, rfc_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, rfc_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Model' : 'RFC',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(data)\n",
    "print(metrics_df)\n",
    "\n",
    "#metrics_df.to_csv('../data/pcaResults.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_gbt = {\n",
    "    'n_estimators': [25, 50, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "gbt = GradientBoostingClassifier()\n",
    "random_search_gbt = RandomizedSearchCV(estimator=gbt, param_distributions=param_dist_gbt, cv=3)\n",
    "random_search_gbt.fit(X_train_pca, y_train)\n",
    "\n",
    "gbt_predictions = random_search_gbt.predict(X_test_pca) \n",
    "print(classification_report(y_val, grid_predictions)) \n",
    "print(confusion_matrix(y_val, grid_predictions))\n",
    "print(\"Best Parameters for GBT:\", random_search_gbt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_val, gbt_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, gbt_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Model' : 'GBT',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(data)\n",
    "print(metrics_df)\n",
    "\n",
    "#metrics_df.to_csv('../data/pcaResults.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea79ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b28bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_xgb = {\n",
    "    'min_child_weight': [40, 50, 60],\n",
    "    'max_delta_step': [0, 1, 2],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'n_estimators': [25, 50, 100],\n",
    "    'Best Params':random_search_gbt.best_params_\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "random_search_xgb = RandomizedSearchCV(estimator=xgb, param_distributions=param_dist_xgb, cv=3)\n",
    "random_search_xgb.fit(X_train_pca, y_train)\n",
    "\n",
    "grid_predictions_xgb = random_search_xgb.predict(X_test_pca)\n",
    "print(classification_report(y_val, grid_predictions_xgb, zero_division=0)) \n",
    "print(confusion_matrix(y_val, grid_predictions_xgb))\n",
    "print(\"Best Parameters for XGBoost:\", random_search_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5cd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_val, grid_predictions_xgb, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, grid_predictions_xgb)\n",
    "params = random_search_xgb.best_params_\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Model' : 'XGBoost',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix],\n",
    "    'Best Params':random_search_xgb.best_params_\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df, ignore_index=True)\n",
    "print(metrics_df)\n",
    "\n",
    "#metrics_df.to_csv('../data/pcaResults.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72103354",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed909c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_light = {\n",
    "    'min_child_weight': [40, 50, 60],\n",
    "    'max_delta_step': [0, 1, 2],\n",
    "    'num_leaves': [20, 30, 40],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'n_estimators': [25, 50, 100],\n",
    "}\n",
    "\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "random_search_lgbm = RandomizedSearchCV(lgbm, param_distributions=param_dist_light, verbose=1, cv=3, n_jobs=-1)\n",
    "random_search_lgbm.fit(X_train_pca, y_train)\n",
    "\n",
    "grid_predictions_lgbm = random_search_lgbm.predict(X_test_pca) \n",
    "print(classification_report(y_val, grid_predictions_lgbm, zero_division=0)) \n",
    "print(confusion_matrix(y_val, grid_predictions_lgbm))\n",
    "print(\"Best Parameters for LGBM:\", random_search_lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_val, grid_predictions_xgb, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, grid_predictions_xgb)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Model' : 'LGBM',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix],\n",
    "    'Best Params':random_search_lgbm.best_params_\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df, ignore_index=True)\n",
    "print(metrics_df)\n",
    "\n",
    "metrics_df.to_csv('../data/tuningResults.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6268ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b6b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
